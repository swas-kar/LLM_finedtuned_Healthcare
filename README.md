
# Fine tuned HealthCare LLM using AWS(Amazon Sagemaker)

## Healthcare Domain Expert Model

## Overview
This project aims to develop a proof of concept (POC) for a domain expert model in the healthcare domain. The model will be trained on a dataset of healthcare-specific knowledge to enhance customer experience and streamline information delivery in healthcare-related applications.

## Objective
The objective of this project is to train a large language model (LLM) to become a domain expert in healthcare. The model should be capable of generating informative, accurate, and contextually relevant text responses related to healthcare topics.

## Dataset
The dataset used for training the model will consist of healthcare-specific text data. This dataset will be used to train the LLM to understand and generate healthcare-specific language and concepts.

## Tools and Technologies
- Amazon Sagemaker: To fine-tune the Meta Llama 2 7B foundation model on the selected healthcare dataset.
- Python: To write the code for deploying, testing, and fine-tuning the model.
- AWS: To deploy and host the fine-tuned model.

## Project Tasks
1. **Fine-tuning the Language Model**: Use Amazon Sagemaker to fine-tune the Meta Llama 2 7B foundation model on the selected healthcare dataset.
2. **Deploy the Fine-tuned Model**: Deploy the fine-tuned model on AWS to make it accessible for generating text responses.
3. **Test and Evaluate the Model**: Test the fine-tuned model for its responses to healthcare-related queries and text-generation tasks.
<div style="display: flex; flex-wrap: wrap;">
    <img src="Screenshot (1281).png" alt="Example6" width="600" height="400" style="margin: 5px;"/>
    <img src="Screenshot (1280).png" alt="Example7" width="600" height="400" style="margin: 5px;"/>
</div>
## Project Impact
This project will contribute to the development of AI-driven solutions in the healthcare domain, enhancing customer experience and improving information delivery in healthcare applications.
